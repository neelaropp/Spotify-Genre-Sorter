Unraveling Musical Genres: A Data-Driven Exploration of Spotify Data
Executive Summary
	We conducted a statistical study using Spotify data to see if clustering methods could properly place songs in their appropriate genre based on different attributes to classify each song. We used k-means and DBSCAN clustering to test two methods on their efficiency to categorize the data. After testing out our methods, we concluded they were overall ineffective to properly place songs in their appropriate genres, and k-means was a better method than DBSCAN for our particular dataset. Despite these results, we did notice that even though there were not multiple distinct genres that formed, there were two large clusters that formed where the first one had more modern music and the second one had older more classical music. Now, let's dive into how the research was conducted and what future studies can be done to improve these results. 
Data Source and Research Topic
	Using a dataset from kaggle, a study using clustering methods was conducted to try and cluster songs into their respective genres based on other attributes. The dataset we used was a dataset from Spotify that included over 300,000 songs, over 5,000 different genres, and the attributes of danceability, energy, speechiness, accousticness, liveness, valence, instrumentalness, and loudness. Using these 8 attributes we created clusters to address our research question. Our main research question for this project was: can we use K-means clustering and DBSCAN to reconstruct music genres using the assigned attributes? 
	All our attributes we chose were on a 1 to 0 scale and were metrics in the form of decimals. Danceability was defined as the suitability for dancing, Energy was defined as the intensity and activity of a song, speechiness was the amount of words and dialect that were in tracks, instrumentalness was the measure of the songs lack of vocals, acousticness was how much a song lacked using electronic songs and more traditional sounds, liveness was the probability that the song was recorded live, valence was a measure of how positive or uplifting the music was, and tempo measured the beats per minute of a song. Before diving into the clustering methods, we found it best to use other visuals like scatterplots, histograms, and pie charts to get a better sense of what the data we were working with consisted of. 
Data Preparation
	Immediately, we used exception handling to account for non numerical cases in our datasets. When initially running the data, errors were encountered for non numerical values in a couple of our columns. Another issue was the need to scale our tempo metric. Tempo was the only value that was measured by beats per minute so we need to scale it to a 1 to 0 scale. In addition to these challenges, there were over 5,000 different genres included in the genre column, and we knew that quickly needed to be narrowed down. In these genres, there was a lot of overlap and super descriptive wording, so we were able to narrow the data set down to these 24 distinct genres: bebop, rock, punk, metal, blues, emo, classical, folk, edm, broadway, house, bluegrass, pop, r&b, funk, soul, rap, indie, country, reggae, hip hop, jam, ska, jazz. After cleaning our data accordingly, we were ready to start visualizing and analyzing it. 
EDA
In our exploratory data analysis, we initially tried using a scatter plot to visualize our data, but due to the sheer number of songs, we weren’t able to reach any clear conclusions. Instead of using a scatter plot to display our data, we used heatmaps, box and whisker plots, histograms, and a pie chart to get a grasp on the data and the patterns we were working with. For the box and whisker plots, we were able to create 8 distinct ones to display how our 8 attributes varied across our genres. Tempo and Liveness appeared to have the least variation with most genres ranging between 100 and 150 beats per minute, and livenes ranging from 0 to 0.35 Out of all our attributes, instrumentalness, and and acousticness varied the most.  After creating the box and whisker plots, we constructed a heatmap to see if we could notice any strong correlation between the different attributes. Out of all the attributes, loudness and energy correlated the most with a correlation of approximately 0.8. Finally, we created a pie chart to show the percent of songs in our dataset that belonged to the respected genres. Overwhelmingly, rock and pop were the largest genres in our dataset.

From our EDA, we were able to determine that pop and rock were the largest genres, loudness and energy had the highest correlation, and some metrics had high amounts of variation between genres while some did not. Overall, it was hard to know if k-means and DBSCAN clustering would be able to create clusters that correlated with our genres, but there were some indicators that our attributes would vary in our clusters. Before discussing the results of our clustering, we’ll dive into what k-means and DBSCAN are. 
K-means
	K-means uses a clustering method involving centroids to form clusters around these centroids. The centroid is a place in the data that is close to the mean of all the data points in that cluster. At first the centroids are randomly placed, but they continue to update their location based on the data as it is read through, and this will repeat until all converge in the data. One of the benefits of k-means is you can predefine the number of clusters that you would like to use to sort your data. This is efficient and scalable, and it made it easier to adjust our clusters to resemble the number of genres we were looking at in our data. We constructed an “elbow graph” to try and find the optimal number of clusters for the most accurate modeling. Although it was difficult to tell from the graph, it appeared roughly 2 clusters would have been optimal. Since we had 24 genres we settled on narrowing those genres down to 13 and set our model to 13 clusters. 
DBSCAN
	The DBSCAN is another clustering method, but unlike the k-means where the number clusters are adjustable, DBSCAN clusters are not adjustable. This method identifies clusters based on a datapoint rather than a set number of clusters. The points are categorized in one of three categories: noise, core or border points. This is defined based on how close they are to other points. Core points have a minimum number of neighbors within their neighborhood, while border points lie within the neighborhood of a core point. DBSCAN begins by randomly selecting a core point and recursively expanding the cluster by adding neighboring core and border points until no more points can be added. 
Application of k-means
	To apply the k-means to our spotify data, we chose to narrow down the 24 music genres to 13, as a couple of the genres were able to fit into one another. Ran a k-means with 13 clusters and we found that each cluster had a more dominant genre in each one. Cluster 1 was EDM, pop and R and B, cluster 2 was high energy music generally, cluster 3 was jazz, cluster 4 was rap and hip hop, cluster 5 was mellow pop, cluster 6 was house, cluster 7 was foreign music, cluster 8 was a mix of rock pop and country, cluster 9 was metal, cluster 10 was blues and bluegrass, cluster 11 was punk and emo, cluster 12 was classical, and finally cluster 13 was folk and broadway. The distinctions between the clusters can be clearly seen in this color coded graph. 
Then, we made  a contingency chart for our k-means data to list out the number of songs from each genre that we had in each cluster. Based on our contingency chart, there were no super obvious standouts among genres dominating a cluster, but it was important to note that the pop genre was most dominant in cluster 1, while rock was most dominant in cluster 8. Then we took an adjusted random index and normalized mutual information in order to see how correlated the clusters were to genre differentiation. Our random index statistic was 0.0707 and our normalized mutual information was 0.171. These showed very low signs of correlation which indicated our k-means model with 13 clusters did a poor job of sorting out the genres. After noticing this, we created a heatmap that showed the patterns of the mean value of our attributes based on each cluster. From the heatmap attributes like instrumentalness, liveness, and danceability varied the most among our clusters. 
	
Application of DBSCAN
	After getting good clusters and results from our k-means, we began the DBSCAN model. This was trickier to get good results, because we could not adjust the number of clusters, and because we had so much data in our data set, there was no clear cluster formation because the data was too dense to spot true outliers and important data points. We eventually settled on a DBSCAN that contained 4 distinct clusters. Our results were skewed, because cluster 0 contained over 75% of the data and considered it our noise, outliers, and extraneous data. Three distinct clusters did form and we were able to make sense of these. Cluster one  contained newer, more electronic genres like pop, rock, and EDM, cluster 2 was slower music like jazz and classical, and cluster 3 was also slower genres like blues, folk, and bluegrass.  The DBSCAN failed to categorize the majority of our data due to the sheer volume of data, but we were able to categorize the remaining songs and notice a clear distinction between older music and newer genres. We then created an additional heat map to model the means of the 8 attributes in all the different clusters for our DBSCAN. It makes sense cluster 0 was noise and outliers in our data, because the mean value appears to be fairly similar across all the attributes. Cluster one appear to have a much lower acousticness and valence than clusters 2 and 3. 
Conclusion
	From our clustering methods, we could conclude that we were unsuccessful with properly categorizing spotify songs into their respective genres. The results of our k-means using 13 clusters showed that while we were able to see clear clusters forming with at least one different dominating genre in each one, the genres were too spread out among each cluster. This indicated that the k-means must have been clustering based on something else instead of genre. Our DBSCAN was even less clear, as most of our data was interpreted as noise and outliers. Although these models were unable to divide the songs into respected genres, they were able to create a stark difference between genres that were less electronic, slower paced and older like classical music, and genres that were faster, more modern and electronic like rock music. This distinction showed that there were two main categories of genres and clustering methods could detect these differences. From the two methods, k-means was a much better method to fit with our dataset. DBSCAN would have been better suited for a smaller dataset with less genres to group songs into. 
Takeaways and Further Research 
	Further research can be done using Spotify datasets to cluster the songs into genres. For this study to be more successful and accurate, subgenres of our genres would have to be made and individual studies would have to be conducted for these. An example would be changing our “rock” genre into subgenres like grunge, nu-metal, alternative rock, indie rock, and pop punk. Then a study using k-means could be done solely on genre classification within rock, and this could be repeated with other genres. Other methods besides clustering could be machine learning and deep learning to better classify spotify genres using attributes. Other methods may deliver more accuracy, and will be able to get closer to a 1:1 correlation. Despite all these methods, one key feature that is missing is the human factor. Computer algorithms may never be able to classify songs into their respected genre as well as the human ear. These clustering methods cannot capture lyrics, chord progressions, spoken language, or the human soul involved in music. However, if a successful method is paired with the human factor of sharing and categorizing new music, it may make creating playlists and connecting people with music much more efficient, and easier for people.  
Appendix: Sources 
https://www.kaggle.com/code/csmohamedayman/spotify-tracks/input?select=dataset.csv
https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/
https://www.youtube.com/watch?v=RDZUdRSDOok
https://www.mathworks.com/help/stats/dbscan.html





 
